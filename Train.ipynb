{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a8052c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from datetime import date, time, timedelta\n",
    "from scipy.fftpack import rfft\n",
    "import warnings\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import KFold, RepeatedKFold, cross_val_score, train_test_split\n",
    "import pickle\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d4485a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading both the insulin set of data\n",
    "insulin_data_1_df = pd.read_csv(\"InsulinData.csv\", low_memory=False)\n",
    "insulin_data_2_df = pd.read_csv(\"Insulin_patient2.csv\" , low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24eda0dd",
   "metadata": {},
   "source": [
    "# Reading both the CGM set of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f79e212a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cgm_data_1_df = pd.read_csv(\"CGMData.csv\", low_memory=False)\n",
    "cgm_data_2_df = pd.read_csv(\"CGM_patient2.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92ded6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def usingOnlyRequiredColumns(insulin_data_1_df,insulin_data_2_df):\n",
    "    \n",
    "    insulin_data_1_df = insulin_data_1_df[[\"Date\", \"Time\", \"BWZ Carb Input (grams)\"]]\n",
    "    insulin_data_2_df = insulin_data_2_df[[\"Date\", \"Time\", \"BWZ Carb Input (grams)\"]]\n",
    "    \n",
    "    # Creating a column called Time stamp\n",
    "    \n",
    "    insulin_data_1_df[\"Timestamp\"] = pd.to_datetime(insulin_data_1_df[\"Date\"] + ' ' + insulin_data_1_df[\"Time\"])\n",
    "    insulin_data_2_df[\"Timestamp\"] = pd.to_datetime(insulin_data_2_df[\"Date\"] + ' ' + insulin_data_2_df[\"Time\"])\n",
    "    \n",
    "    return insulin_data_1_df, insulin_data_2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ad2f066",
   "metadata": {},
   "outputs": [],
   "source": [
    "insulin_data_1_df, insulin_data_2_df = usingOnlyRequiredColumns(insulin_data_1_df, insulin_data_2_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "550e7f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def usingOnlyRequiredColumns_cgm(cgm_data_1_df,cgm_data_2_df):\n",
    "    \n",
    "    cgm_data_1_df   = cgm_data_1_df[[\"Date\", \"Time\", \"Sensor Glucose (mg/dL)\"]]\n",
    "    cgm_data_2_df  = cgm_data_2_df[[\"Date\", \"Time\", \"Sensor Glucose (mg/dL)\"]]\n",
    "    \n",
    "    # Creating a column called Time stamp\n",
    "    \n",
    "    cgm_data_1_df[\"Timestamp\"] = pd.to_datetime(cgm_data_1_df[\"Date\"] + ' ' + cgm_data_1_df[\"Time\"])\n",
    "    cgm_data_2_df[\"Timestamp\"] = pd.to_datetime(cgm_data_2_df[\"Date\"] + ' ' + cgm_data_2_df[\"Time\"])\n",
    "    \n",
    "    return cgm_data_1_df, cgm_data_2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca00500a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cgm_data_1_df, cgm_data_2_df = usingOnlyRequiredColumns_cgm(cgm_data_1_df, cgm_data_2_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e94980",
   "metadata": {},
   "source": [
    "# Checking our new dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8efb3efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaningUpInsulinData(insulin_data_1_df, insulin_data_2_df):\n",
    "    \n",
    "#     Working on insulin data set - I\n",
    "#     Setting up the index to Timestamp\n",
    "#     Sorting values based on Timestamp\n",
    "    \n",
    "\n",
    "    insulin_data_1_df_copy = insulin_data_1_df.copy()  \n",
    "    insulin_data_1_df_copy = insulin_data_1_df_copy.set_index('Timestamp')\n",
    "    insulin_data_1_df_copy = insulin_data_1_df_copy.sort_values(by=\"Timestamp\" , ascending=True)\n",
    "    insulin_data_1_df_copy = insulin_data_1_df_copy.dropna().reset_index()\n",
    "    insulin_data_1_df_copy['BWZ Carb Input (grams)'].replace(0.0, np.nan, inplace=True)\n",
    "    insulin_data_1_df_copy = insulin_data_1_df_copy.dropna()\n",
    "    insulin_data_1_df_copy = insulin_data_1_df_copy.reset_index().drop(columns=\"index\")\n",
    "\n",
    "    \n",
    "    \n",
    "    insulin_data_2_df_copy = insulin_data_2_df.copy()\n",
    "    insulin_data_2_df_copy = insulin_data_2_df_copy.set_index('Timestamp')\n",
    "    insulin_data_2_df_copy = insulin_data_2_df_copy.sort_values(by=\"Timestamp\", ascending=True)\n",
    "    insulin_data_2_df_copy = insulin_data_2_df_copy.dropna().reset_index()\n",
    "    insulin_data_2_df_copy['BWZ Carb Input (grams)'].replace(0.0, np.nan, inplace=True)\n",
    "    insulin_data_2_df_copy = insulin_data_2_df_copy.dropna()\n",
    "    insulin_data_2_df_copy = insulin_data_2_df_copy.reset_index().drop(columns=\"index\")\n",
    "    \n",
    "    return insulin_data_1_df_copy, insulin_data_2_df_copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97373be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "insulin_data_1_df_new, insulin_data_2_df_new = cleaningUpInsulinData(insulin_data_1_df, insulin_data_2_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69cdfa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creatingList(insulin_data_1_df_new):\n",
    "    valid_timestamp_list = []\n",
    "    two_hour_thirty_mins = 150\n",
    "    for index, ts in enumerate(insulin_data_1_df_new['Timestamp']):\n",
    "        try:\n",
    "            valid_tm = (insulin_data_1_df_new['Timestamp'][index+1] -ts).seconds / 60.0\n",
    "            if valid_tm >=150:\n",
    "                valid_timestamp_list.append(ts)\n",
    "                \n",
    "        except KeyError:\n",
    "            break\n",
    "    \n",
    "    return valid_timestamp_list      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e573a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching the valid timestamp list from the insulin data:\n",
    "\n",
    "valid_timestamp_list_1 = creatingList(insulin_data_1_df_new)\n",
    "valid_timestamp_list_2 = creatingList(insulin_data_2_df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed88c626",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creatingMealData(valid_timestamp_list, cgm_data_1_df):\n",
    "    \n",
    "    cgmDataList = []\n",
    "    \n",
    "    for index, ts in enumerate(valid_timestamp_list):\n",
    "        start_offset_thirty_minutes = pd.to_datetime(ts - pd.Timedelta(value=30, unit=\"T\"))\n",
    "        end_offset_oneTwenty_minutes = pd.to_datetime(ts - pd.Timedelta(value=2, unit=\"H\"))\n",
    "        fetch_date = ts.date().strftime('%-m/%-d/%Y')\n",
    "        cgmDataList.append(cgm_data_1_df.loc[cgm_data_1_df['Date']==fetch_date].set_index('Timestamp').between_time\n",
    "                           (start_time=start_offset_thirty_minutes.strftime('%-H:%-M:%-S'),\n",
    "                            end_time=end_offset_oneTwenty_minutes.strftime('%-H:%-M:%-S'))['Sensor Glucose (mg/dL)'].values.tolist())\n",
    "    return pd.DataFrame(cgmDataList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c45a9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creatingMealData_2(valid_timestamp_list_2, cgm_data_2_df):\n",
    "     \n",
    "    cgmDataList_2 = []\n",
    "    \n",
    "    for index, ts in enumerate(valid_timestamp_list_2):\n",
    "        start_offset_thirty_minutes = pd.to_datetime(ts - pd.Timedelta(value=30, unit=\"T\"))\n",
    "        end_offset_oneTwenty_minutes = pd.to_datetime(ts - pd.Timedelta(value=2, unit=\"H\"))\n",
    "        fetch_date = ts.date().strftime('%Y-%m-%d')\n",
    "        cgmDataList_2.append(cgm_data_2_df.loc[cgm_data_2_df['Date']==fetch_date].set_index('Timestamp').between_time\n",
    "                           (start_time=start_offset_thirty_minutes.strftime('%H:%M:%S'),\n",
    "                            end_time=end_offset_oneTwenty_minutes.strftime('%H:%M:%S'))['Sensor Glucose (mg/dL)'].values.tolist())\n",
    "    return pd.DataFrame(cgmDataList_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a071743d",
   "metadata": {},
   "outputs": [],
   "source": [
    "meal_df_1 = creatingMealData(valid_timestamp_list_1, cgm_data_1_df)\n",
    "meal_df_2 = creatingMealData_2(valid_timestamp_list_2, cgm_data_2_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0760bf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "meal_df_1 = meal_df_1.iloc[:,0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4bd2c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "meal_df_2 = meal_df_2.iloc[:,0:30]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9eeaaa52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noMealData(insulin_data_1_df_new,cgm_data_1_df):\n",
    "    valid_timestamp_list_no_meal = []\n",
    "    for index, ts in enumerate(insulin_data_1_df_new[\"Timestamp\"]):\n",
    "        try:\n",
    "            value = (insulin_data_1_df_new[\"Timestamp\"][index+1] - ts).seconds/3600\n",
    "            if value >=4 :\n",
    "                valid_timestamp_list_no_meal.append(ts)\n",
    "        except KeyError:\n",
    "            break\n",
    "\n",
    "    no_meal_data_list_1 = []\n",
    "\n",
    "    for index, ts in enumerate(valid_timestamp_list_no_meal):\n",
    "        start_offset_two_hours = pd.to_datetime(ts + pd.Timedelta(value=2, unit=\"H\"))\n",
    "        end_offset_two_hours = pd.to_datetime(start_offset_two_hours + pd.Timedelta(value=2, unit=\"H\"))\n",
    "        get_date = ts.date().strftime('%-m/%-d/%Y')\n",
    "        no_meal_data_list_1.append(cgm_data_1_df.loc[cgm_data_1_df['Date']==get_date].set_index('Timestamp').between_time\n",
    "                      (start_time=start_offset_two_hours.strftime('%-H:%-M:%-S'),\n",
    "                       end_time=end_offset_two_hours.strftime('%-H:%-M:%-S'))['Sensor Glucose (mg/dL)'].values.tolist())\n",
    "    return pd.DataFrame(no_meal_data_list_1)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64f01919",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_meal_df_1 = noMealData(insulin_data_1_df_new, cgm_data_1_df)\n",
    "no_meal_df_1 = no_meal_df_1.iloc[:,0:24]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9daebdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noMealData_2(insulin_data_2_df_new,cgm_data_2_df):\n",
    "    valid_timestamp_list_no_meal = []\n",
    "    for index, ts in enumerate(insulin_data_2_df_new[\"Timestamp\"]):\n",
    "        try:\n",
    "            value = (insulin_data_2_df_new[\"Timestamp\"][index+1] - ts).seconds/3600\n",
    "            if value >=4 :\n",
    "                valid_timestamp_list_no_meal.append(ts)\n",
    "        except KeyError:\n",
    "            break\n",
    "\n",
    "    no_meal_data_list_2 = []\n",
    "\n",
    "    for index, ts in enumerate(valid_timestamp_list_no_meal):\n",
    "        start_offset_two_hours = pd.to_datetime(ts + pd.Timedelta(value=2, unit=\"H\"))\n",
    "        end_offset_two_hours = pd.to_datetime(start_offset_two_hours + pd.Timedelta(value=2, unit=\"H\"))\n",
    "        get_date = ts.date().strftime('%Y-%m-%d')\n",
    "        no_meal_data_list_2.append(cgm_data_2_df.loc[cgm_data_2_df['Date']==get_date].set_index('Timestamp').between_time\n",
    "                      (start_time=start_offset_two_hours.strftime('%-H:%-M:%-S'),\n",
    "                       end_time=end_offset_two_hours.strftime('%-H:%-M:%-S'))['Sensor Glucose (mg/dL)'].values.tolist())\n",
    "    return pd.DataFrame(no_meal_data_list_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a340d3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_meal_df_2 = noMealData_2(insulin_data_2_df_new, cgm_data_2_df)\n",
    "no_meal_df_2 = no_meal_df_2.iloc[:,0:24]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977a193c",
   "metadata": {},
   "source": [
    "#### Feature Extraction workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7864700f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_meal_data(meal_df):\n",
    "    \n",
    "    indexes_to_clean = meal_df.isna().sum(axis=1).replace(0,np.nan).dropna().where(lambda x: x > 6).dropna().index\n",
    "    \n",
    "    meal_cleaned_df = meal_df.drop(meal_df.index[indexes_to_clean]).reset_index().drop(columns=\"index\")\n",
    "    \n",
    "    meal_cleaned_df = meal_cleaned_df.interpolate(method='linear', axis=1)\n",
    "    \n",
    "    return meal_cleaned_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "74fa03c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "meal_cleaned_df_1 = cleaning_meal_data(meal_df_1)\n",
    "meal_cleaned_df_2 = cleaning_meal_data(meal_df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e7234c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createMealFeatureDataMatrix(meal_cleaned_df):\n",
    "    power_second_max = []\n",
    "    power_third_max = []\n",
    "    List1=[]\n",
    "    differential_data = []\n",
    "    standard_deviation = []\n",
    "    for i in range(len(meal_cleaned_df)):\n",
    "        array = abs(rfft(meal_cleaned_df.iloc[:,0:30].iloc[i].values.tolist())).tolist()\n",
    "        sorted_array = abs(rfft(meal_cleaned_df.iloc[:,0:30].iloc[i].values.tolist())).tolist()\n",
    "        sorted_array.sort()\n",
    "    \n",
    "        power_second_max.append(sorted_array[-3])\n",
    "        power_third_max.append(sorted_array[-4])\n",
    "    \n",
    "    TimeMeal = meal_cleaned_df.iloc[:,22:25].idxmin(axis=1)\n",
    "    MaximumGlucoseLevels = meal_cleaned_df.iloc[:,5:19].idxmax(axis=1)\n",
    "\n",
    "\n",
    "    for i in range(len(meal_cleaned_df)):\n",
    "        List1.append(np.diff(meal_cleaned_df.iloc[:,MaximumGlucoseLevels[i]:TimeMeal[i]].iloc[i].tolist()).max())\n",
    "        differential_data.append(np.diff(meal_cleaned_df.iloc[:,MaximumGlucoseLevels[i]:TimeMeal[i]].iloc[i].tolist()).max())\n",
    "        standard_deviation.append(np.std(meal_cleaned_df.iloc[i]))\n",
    "    \n",
    "    meal_data_feature_matrix = pd.DataFrame()\n",
    "    meal_data_feature_matrix['Power II Max'] = power_second_max\n",
    "    meal_data_feature_matrix['Power III Max'] = power_third_max\n",
    "    meal_data_feature_matrix['II Differential'] = differential_data\n",
    "    meal_data_feature_matrix['Standard Deviation'] = standard_deviation\n",
    "\n",
    "    return meal_data_feature_matrix\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d817aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "meal_feature_matrix_1 = createMealFeatureDataMatrix(meal_cleaned_df_1)\n",
    "meal_feature_matrix_2 = createMealFeatureDataMatrix(meal_cleaned_df_2)\n",
    "meal_feature_matrix=pd.concat([meal_feature_matrix_1,meal_feature_matrix_2]).reset_index().drop(columns='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8ce23b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_no_meal_data(no_meal_df):\n",
    "    \n",
    "    indexes_to_clean = no_meal_df.isna().sum(axis=1).replace(0,np.nan).dropna().where(lambda x: x > 6).dropna().index\n",
    "    \n",
    "    no_meal_cleaned_df = no_meal_df.drop(no_meal_df.index[indexes_to_clean]).reset_index().drop(columns=\"index\")\n",
    "    \n",
    "    no_meal_cleaned_df = no_meal_cleaned_df.interpolate(method='linear', axis=1)\n",
    "    \n",
    "    return no_meal_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4faeeffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_meal_cleaned_df_1 = cleaning_meal_data(no_meal_df_1)\n",
    "no_meal_cleaned_df_2 = cleaning_meal_data(no_meal_df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "662689c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createNoMealFeatureDataMatrix(no_meal_cleaned_df):\n",
    "    power_second_max = []\n",
    "    power_third_max = []\n",
    "    differential_data = []\n",
    "    standard_deviation = []\n",
    "    for i in range(len(no_meal_cleaned_df)):\n",
    "        array = abs(rfft(no_meal_cleaned_df.iloc[:,0:24].iloc[i].values.tolist())).tolist()\n",
    "        sorted_array = abs(rfft(no_meal_cleaned_df.iloc[:,0:24].iloc[i].values.tolist())).tolist()\n",
    "        sorted_array.sort()\n",
    "    \n",
    "        power_second_max.append(sorted_array[-3])\n",
    "        power_third_max.append(sorted_array[-4])\n",
    "\n",
    "    for i in range(len(no_meal_cleaned_df)):\n",
    "        differential_data.append(np.diff(np.diff(no_meal_cleaned_df.iloc[:,0:24].iloc[i].tolist())).max())\n",
    "        standard_deviation.append(np.std(no_meal_cleaned_df.iloc[i]))\n",
    "    \n",
    "    no_meal_data_feature_matrix = pd.DataFrame()\n",
    "    no_meal_data_feature_matrix['Power II Max'] = power_second_max\n",
    "    no_meal_data_feature_matrix['Power III Max'] = power_third_max\n",
    "    no_meal_data_feature_matrix['II Differential'] = differential_data\n",
    "    no_meal_data_feature_matrix['Standard Deviation'] = standard_deviation\n",
    "\n",
    "    return no_meal_data_feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "02652f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_meal_feature_matrix_1 = createNoMealFeatureDataMatrix(no_meal_cleaned_df_1)\n",
    "no_meal_feature_matrix_2 = createNoMealFeatureDataMatrix(no_meal_cleaned_df_2)\n",
    "no_meal_feature_matrix = pd.concat([no_meal_feature_matrix_1, no_meal_feature_matrix_2]).reset_index().drop(columns=\"index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb82d2b9",
   "metadata": {},
   "source": [
    "### Both Data Feature extraction Matrix for meal and no meal data are ready\n",
    "\n",
    "1. Meal Data Matrix name is : meal_feature_matrix\n",
    "2. No Meal Data Matrix name is : no_meal_feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c424f775",
   "metadata": {},
   "outputs": [],
   "source": [
    "meal_feature_matrix['ClassLabel'] = 1\n",
    "no_meal_feature_matrix['ClassLabel'] = 0\n",
    "\n",
    "total_dataset = pd.concat([meal_feature_matrix, no_meal_feature_matrix]).reset_index().drop(columns=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f74e0bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_dataset = total_dataset.dropna().reset_index().drop(columns=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4cb52811",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "dataset=shuffle(total_dataset,random_state=1).reset_index().drop(columns='index')\n",
    "X = dataset.drop(\"ClassLabel\", axis = 1)\n",
    "y = dataset[\"ClassLabel\"]\n",
    "\n",
    "# Splitting the test and training model using the 80-20 % proportion 80% training, 20% testing or validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y, \n",
    "                                                    test_size=0.2)\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "db9cefc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score with cross validation five : 91.55%\n",
      "Precision score with cross validation five : 88.80%\n",
      "Recall score with cross validation five : 96.79%\n",
      "F-1 score with cross validation five : 92.53%\n",
      "Single validation score without cross validation :93.31%\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "clf_single_score = clf.score(X_test, y_test)\n",
    "\n",
    "## Cross validation k-folds = 5 score : Accuracy\n",
    "clf_cross_val_score_accuracy = np.mean(cross_val_score(clf, \n",
    "                                                       X, \n",
    "                                                       y, cv=5,\n",
    "                                                       scoring=\"accuracy\"))\n",
    "\n",
    "## Cross validation k-folds = 5, score : Precision\n",
    "\n",
    "clf_cross_val_score_precision = np.mean(cross_val_score(clf,\n",
    "                                                       X,\n",
    "                                                       y,\n",
    "                                                       cv=5,\n",
    "                                                       scoring=\"precision\"))\n",
    "## Cross validation k-folds = 5, score : Recall\n",
    "\n",
    "clf_cross_val_score_recall = np.mean(cross_val_score(clf,\n",
    "                                                    X,\n",
    "                                                    y,\n",
    "                                                    cv=5,\n",
    "                                                    scoring=\"recall\"))\n",
    "\n",
    "## Cross validation k-folds = 5, score : F1 score\n",
    "\n",
    "clf_cross_val_score_f1 = np.mean(cross_val_score(clf,\n",
    "                                                X,\n",
    "                                                y,\n",
    "                                                cv=5,\n",
    "                                                scoring=\"f1\"))\n",
    "\n",
    "\n",
    "print(f\"Accuracy score with cross validation five : {(clf_cross_val_score_accuracy) * 100:.2f}%\")\n",
    "print(f\"Precision score with cross validation five : {(clf_cross_val_score_precision) * 100:.2f}%\")\n",
    "print(f\"Recall score with cross validation five : {(clf_cross_val_score_recall) * 100:.2f}%\")\n",
    "print(f\"F-1 score with cross validation five : {(clf_cross_val_score_f1) * 100:.2f}%\")\n",
    "print(f\"Single validation score without cross validation :{(clf_single_score) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f49c224",
   "metadata": {},
   "source": [
    "### Saving and loading trained machine learning models\n",
    "\n",
    "1. Python `pickle()` module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a2a82bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save an existing model to file\n",
    "pickle.dump(clf, open('clf_random_forest_classifier.pkl', \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872d62bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
